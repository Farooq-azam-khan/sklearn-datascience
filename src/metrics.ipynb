{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12abe43-4333-46aa-906d-11a740423e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e515fce-5b4a-43a9-bd7f-e184102e12af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/creditcard.csv')[:80_000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac5fed0-441a-4caf-a8d8-f96bb1a8732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5061dc19-ffa4-49df-82db-1c4ed229b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of X, y = (80000, 28), (80000,)\n",
      "#Fraud Cases = 196\n"
     ]
    }
   ],
   "source": [
    "print(f'Shapes of X, y = {X.shape}, {y.shape}')\n",
    "print(f'#Fraud Cases = {y.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "208dd4a2-aae3-49ef-8372-0c1443b1dcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1_000)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c60feacc-dff2-4a48-9cc5-6b02bddf806e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a957985c-8e14-4e2c-93d2-bf2242db2b70",
   "metadata": {},
   "source": [
    "# Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8d6b846-5e77-4ab2-975d-47b4f3b6b9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={0:1, 1:2}, max_iter=1_000)\n",
    "model.fit(X,y).predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46b7e2e7-3c13-4731-8391-3c5e0de794cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1_000),\n",
    "    param_grid={'class_weight': [{0:1, 1:v} for v in range(1, 4)]},\n",
    "    cv=10, \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d1f406-2f1e-4ab1-86bc-3e4c157789ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "526c1aab-3484-403e-a098-deb8b14c1143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.655691</td>\n",
       "      <td>0.405497</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1}}</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.997250</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.998375</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.998375</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.998463</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.559392</td>\n",
       "      <td>0.406982</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2}}</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0.997250</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.998375</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.998675</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.162384</td>\n",
       "      <td>0.424557</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3}}</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.999125</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.655691      0.405497         0.004600        0.002858   \n",
       "1       3.559392      0.406982         0.004969        0.005931   \n",
       "2       3.162384      0.424557         0.002304        0.002998   \n",
       "\n",
       "  param_class_weight                          params  split0_test_score  \\\n",
       "0       {0: 1, 1: 1}  {'class_weight': {0: 1, 1: 1}}           0.998500   \n",
       "1       {0: 1, 1: 2}  {'class_weight': {0: 1, 1: 2}}           0.998625   \n",
       "2       {0: 1, 1: 3}  {'class_weight': {0: 1, 1: 3}}           0.999250   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.997250           0.998125           0.998750           0.998375   \n",
       "1           0.997250           0.998125           0.999625           0.998375   \n",
       "2           0.997125           0.998125           0.999625           0.998500   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0             0.9995           0.999750           0.998375           0.997500   \n",
       "1             0.9995           0.999875           0.998500           0.998125   \n",
       "2             0.9995           0.999875           0.998500           0.998125   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.998500         0.998463        0.000731                3  \n",
       "1           0.998750         0.998675        0.000761                2  \n",
       "2           0.999125         0.998775        0.000808                1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09b4c8-1129-4539-b214-71fd36df6cbe",
   "metadata": {},
   "source": [
    "# Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a127e52-417b-42e4-bc6a-369ba11d29ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of LogisticRegression()>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd2a3bed-afa3-4984-8c05-e8a2e6f99149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"\n",
       "        Return the mean accuracy on the given test data and labels.\n",
       "\n",
       "        In multi-label classification, this is the subset accuracy\n",
       "        which is a harsh metric since you require for each sample that\n",
       "        each label set be correctly predicted.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : array-like of shape (n_samples, n_features)\n",
       "            Test samples.\n",
       "\n",
       "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "            True labels for `X`.\n",
       "\n",
       "        sample_weight : array-like of shape (n_samples,), default=None\n",
       "            Sample weights.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        score : float\n",
       "            Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\farooq khan\\desktop\\dev\\sklearn-datascience\\venv\\lib\\site-packages\\sklearn\\base.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??lr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb00a30d-8416-425e-bbab-74cdcaac2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdcc4e00-3899-46d7-9307-77c5df365069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8055555555555556, Recall: 0.7397959183673469\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {precision_score(y, grid.predict(X))}, Recall: {recall_score(y, grid.predict(X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e968b-4c8e-4745-98db-7a59e152ea9d",
   "metadata": {},
   "source": [
    "- Precision asks, give that I predicted fraud, how accurate am I?\n",
    "- Recall asks, did I get all the fraud cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "015ed1a9-15a2-44d1-a0be-3760e03c86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "grid_metric = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1_000),\n",
    "    param_grid={'class_weight': [{0:1, 1:v} for v in np.linspace(1,20,30)]},\n",
    "    scoring={'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score)},\n",
    "    refit='precision', # optimize over precision\n",
    "    cv=10, \n",
    "    return_train_score = True, \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af0b06fd-c26a-48c4-8745-92a592771397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 14.758620689655173},\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit='precision', return_train_score=True,\n",
       "             scoring={'precision': make_scorer(precision_score),\n",
       "                      'recall': make_scorer(recall_score)})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_metric.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4404892-2298-4799-ada0-64f4702b92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_recall</th>\n",
       "      <th>split3_train_recall</th>\n",
       "      <th>split4_train_recall</th>\n",
       "      <th>split5_train_recall</th>\n",
       "      <th>split6_train_recall</th>\n",
       "      <th>split7_train_recall</th>\n",
       "      <th>split8_train_recall</th>\n",
       "      <th>split9_train_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>std_train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.658586</td>\n",
       "      <td>0.441277</td>\n",
       "      <td>0.016630</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>{0: 1, 1: 1.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.0}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.612185</td>\n",
       "      <td>0.054733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.372206</td>\n",
       "      <td>0.454490</td>\n",
       "      <td>0.018593</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>{0: 1, 1: 1.6551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.6551724137931034}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.680239</td>\n",
       "      <td>0.050286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.321204</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>{0: 1, 1: 2.310344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.310344827586207}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.724454</td>\n",
       "      <td>0.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.436434</td>\n",
       "      <td>0.416475</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>{0: 1, 1: 2.9655172413793105}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.9655172413793105}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.732955</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.749978</td>\n",
       "      <td>0.039589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.848136</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>{0: 1, 1: 3.6206896551724137}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.6206896551724137}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.771498</td>\n",
       "      <td>0.037959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.029555</td>\n",
       "      <td>0.590561</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>{0: 1, 1: 4.275862068965517}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.275862068965517}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.792485</td>\n",
       "      <td>0.029289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.129444</td>\n",
       "      <td>0.288047</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>{0: 1, 1: 4.931034482758621}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.931034482758621}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.812327</td>\n",
       "      <td>0.021063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.972758</td>\n",
       "      <td>0.452708</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>{0: 1, 1: 5.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.586206896551724}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.827080</td>\n",
       "      <td>0.017190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.104741</td>\n",
       "      <td>0.400176</td>\n",
       "      <td>0.018332</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>{0: 1, 1: 6.241379310344827}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.241379310344827}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.838431</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.149776</td>\n",
       "      <td>0.587266</td>\n",
       "      <td>0.018041</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>{0: 1, 1: 6.896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.896551724137931}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.844665</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.997608</td>\n",
       "      <td>0.309018</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>{0: 1, 1: 7.551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.551724137931034}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.848064</td>\n",
       "      <td>0.010502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.188330</td>\n",
       "      <td>0.514553</td>\n",
       "      <td>0.019851</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>{0: 1, 1: 8.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.206896551724139}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852038</td>\n",
       "      <td>0.009997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.170189</td>\n",
       "      <td>0.549605</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>{0: 1, 1: 8.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.862068965517242}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.011103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.128623</td>\n",
       "      <td>0.680782</td>\n",
       "      <td>0.019492</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>{0: 1, 1: 9.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.517241379310345}}</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.855441</td>\n",
       "      <td>0.011414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.114862</td>\n",
       "      <td>0.371848</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>{0: 1, 1: 10.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.172413793103448}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856009</td>\n",
       "      <td>0.011097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.182712</td>\n",
       "      <td>0.677473</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>{0: 1, 1: 10.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.827586206896552}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.856577</td>\n",
       "      <td>0.011881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.053327</td>\n",
       "      <td>0.307612</td>\n",
       "      <td>0.019224</td>\n",
       "      <td>0.008371</td>\n",
       "      <td>{0: 1, 1: 11.482758620689655}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.482758620689655}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.859415</td>\n",
       "      <td>0.011778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.288990</td>\n",
       "      <td>0.371278</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>{0: 1, 1: 12.137931034482758}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.137931034482758}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.862811</td>\n",
       "      <td>0.011843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.061701</td>\n",
       "      <td>0.322787</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>{0: 1, 1: 12.793103448275861}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.793103448275861}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.864513</td>\n",
       "      <td>0.012530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.319620</td>\n",
       "      <td>0.420592</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>{0: 1, 1: 13.448275862068964}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.448275862068964}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866214</td>\n",
       "      <td>0.010798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.067455</td>\n",
       "      <td>0.248226</td>\n",
       "      <td>0.017271</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>{0: 1, 1: 14.103448275862068}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.103448275862068}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866782</td>\n",
       "      <td>0.011092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.323480</td>\n",
       "      <td>0.326185</td>\n",
       "      <td>0.017322</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>{0: 1, 1: 14.758620689655173}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.758620689655173}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.010509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.274531</td>\n",
       "      <td>0.351363</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>{0: 1, 1: 15.413793103448276}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.413793103448276}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867915</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.944623</td>\n",
       "      <td>0.398780</td>\n",
       "      <td>0.017648</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>{0: 1, 1: 16.06896551724138}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.06896551724138}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.467752</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.020824</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>{0: 1, 1: 16.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.724137931034484}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.912173</td>\n",
       "      <td>0.442908</td>\n",
       "      <td>0.020079</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>{0: 1, 1: 17.379310344827587}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.379310344827587}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869617</td>\n",
       "      <td>0.009789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.361750</td>\n",
       "      <td>0.490835</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>{0: 1, 1: 18.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.03448275862069}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.870185</td>\n",
       "      <td>0.010851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.266036</td>\n",
       "      <td>0.294932</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>{0: 1, 1: 18.689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.689655172413794}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.349838</td>\n",
       "      <td>0.414099</td>\n",
       "      <td>0.018365</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>{0: 1, 1: 19.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.344827586206897}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.872458</td>\n",
       "      <td>0.011025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.930055</td>\n",
       "      <td>0.366691</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873588</td>\n",
       "      <td>0.010104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        3.658586      0.441277         0.016630        0.002751   \n",
       "1        3.372206      0.454490         0.018593        0.004198   \n",
       "2        3.321204      0.375700         0.017427        0.004376   \n",
       "3        3.436434      0.416475         0.018141        0.006871   \n",
       "4        2.848136      0.525705         0.018755        0.004254   \n",
       "5        3.029555      0.590561         0.016272        0.002330   \n",
       "6        3.129444      0.288047         0.018873        0.005818   \n",
       "7        2.972758      0.452708         0.018228        0.004968   \n",
       "8        3.104741      0.400176         0.018332        0.004105   \n",
       "9        3.149776      0.587266         0.018041        0.003273   \n",
       "10       2.997608      0.309018         0.020106        0.003141   \n",
       "11       3.188330      0.514553         0.019851        0.005529   \n",
       "12       3.170189      0.549605         0.017213        0.003552   \n",
       "13       3.128623      0.680782         0.019492        0.008961   \n",
       "14       3.114862      0.371848         0.019407        0.007192   \n",
       "15       3.182712      0.677473         0.021452        0.009642   \n",
       "16       3.053327      0.307612         0.019224        0.008371   \n",
       "17       3.288990      0.371278         0.017476        0.004291   \n",
       "18       3.061701      0.322787         0.018252        0.004521   \n",
       "19       3.319620      0.420592         0.017937        0.003101   \n",
       "20       3.067455      0.248226         0.017271        0.002414   \n",
       "21       3.323480      0.326185         0.017322        0.001735   \n",
       "22       3.274531      0.351363         0.017686        0.002448   \n",
       "23       2.944623      0.398780         0.017648        0.003080   \n",
       "24       3.467752      0.554955         0.020824        0.007475   \n",
       "25       2.912173      0.442908         0.020079        0.005053   \n",
       "26       3.361750      0.490835         0.015952        0.003717   \n",
       "27       3.266036      0.294932         0.016545        0.003831   \n",
       "28       3.349838      0.414099         0.018365        0.006899   \n",
       "29       2.930055      0.366691         0.013692        0.003605   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 1.0}   \n",
       "1   {0: 1, 1: 1.6551724137931034}   \n",
       "2    {0: 1, 1: 2.310344827586207}   \n",
       "3   {0: 1, 1: 2.9655172413793105}   \n",
       "4   {0: 1, 1: 3.6206896551724137}   \n",
       "5    {0: 1, 1: 4.275862068965517}   \n",
       "6    {0: 1, 1: 4.931034482758621}   \n",
       "7    {0: 1, 1: 5.586206896551724}   \n",
       "8    {0: 1, 1: 6.241379310344827}   \n",
       "9    {0: 1, 1: 6.896551724137931}   \n",
       "10   {0: 1, 1: 7.551724137931034}   \n",
       "11   {0: 1, 1: 8.206896551724139}   \n",
       "12   {0: 1, 1: 8.862068965517242}   \n",
       "13   {0: 1, 1: 9.517241379310345}   \n",
       "14  {0: 1, 1: 10.172413793103448}   \n",
       "15  {0: 1, 1: 10.827586206896552}   \n",
       "16  {0: 1, 1: 11.482758620689655}   \n",
       "17  {0: 1, 1: 12.137931034482758}   \n",
       "18  {0: 1, 1: 12.793103448275861}   \n",
       "19  {0: 1, 1: 13.448275862068964}   \n",
       "20  {0: 1, 1: 14.103448275862068}   \n",
       "21  {0: 1, 1: 14.758620689655173}   \n",
       "22  {0: 1, 1: 15.413793103448276}   \n",
       "23   {0: 1, 1: 16.06896551724138}   \n",
       "24  {0: 1, 1: 16.724137931034484}   \n",
       "25  {0: 1, 1: 17.379310344827587}   \n",
       "26   {0: 1, 1: 18.03448275862069}   \n",
       "27  {0: 1, 1: 18.689655172413794}   \n",
       "28  {0: 1, 1: 19.344827586206897}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 1.0}}               1.000000   \n",
       "1   {'class_weight': {0: 1, 1: 1.6551724137931034}}               1.000000   \n",
       "2    {'class_weight': {0: 1, 1: 2.310344827586207}}               1.000000   \n",
       "3   {'class_weight': {0: 1, 1: 2.9655172413793105}}               1.000000   \n",
       "4   {'class_weight': {0: 1, 1: 3.6206896551724137}}               1.000000   \n",
       "5    {'class_weight': {0: 1, 1: 4.275862068965517}}               1.000000   \n",
       "6    {'class_weight': {0: 1, 1: 4.931034482758621}}               1.000000   \n",
       "7    {'class_weight': {0: 1, 1: 5.586206896551724}}               1.000000   \n",
       "8    {'class_weight': {0: 1, 1: 6.241379310344827}}               0.944444   \n",
       "9    {'class_weight': {0: 1, 1: 6.896551724137931}}               0.944444   \n",
       "10   {'class_weight': {0: 1, 1: 7.551724137931034}}               0.944444   \n",
       "11   {'class_weight': {0: 1, 1: 8.206896551724139}}               0.944444   \n",
       "12   {'class_weight': {0: 1, 1: 8.862068965517242}}               0.944444   \n",
       "13   {'class_weight': {0: 1, 1: 9.517241379310345}}               0.894737   \n",
       "14  {'class_weight': {0: 1, 1: 10.172413793103448}}               0.850000   \n",
       "15  {'class_weight': {0: 1, 1: 10.827586206896552}}               0.850000   \n",
       "16  {'class_weight': {0: 1, 1: 11.482758620689655}}               0.857143   \n",
       "17  {'class_weight': {0: 1, 1: 12.137931034482758}}               0.857143   \n",
       "18  {'class_weight': {0: 1, 1: 12.793103448275861}}               0.857143   \n",
       "19  {'class_weight': {0: 1, 1: 13.448275862068964}}               0.818182   \n",
       "20  {'class_weight': {0: 1, 1: 14.103448275862068}}               0.818182   \n",
       "21  {'class_weight': {0: 1, 1: 14.758620689655173}}               0.818182   \n",
       "22  {'class_weight': {0: 1, 1: 15.413793103448276}}               0.818182   \n",
       "23   {'class_weight': {0: 1, 1: 16.06896551724138}}               0.782609   \n",
       "24  {'class_weight': {0: 1, 1: 16.724137931034484}}               0.782609   \n",
       "25  {'class_weight': {0: 1, 1: 17.379310344827587}}               0.782609   \n",
       "26   {'class_weight': {0: 1, 1: 18.03448275862069}}               0.782609   \n",
       "27  {'class_weight': {0: 1, 1: 18.689655172413794}}               0.782609   \n",
       "28  {'class_weight': {0: 1, 1: 19.344827586206897}}               0.782609   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}               0.782609   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                0.463415               0.583333               1.000000  ...   \n",
       "1                0.463415               0.583333               1.000000  ...   \n",
       "2                0.463415               0.583333               1.000000  ...   \n",
       "3                0.452381               0.583333               1.000000  ...   \n",
       "4                0.452381               0.583333               1.000000  ...   \n",
       "5                0.452381               0.583333               1.000000  ...   \n",
       "6                0.452381               0.583333               1.000000  ...   \n",
       "7                0.452381               0.583333               1.000000  ...   \n",
       "8                0.452381               0.583333               0.947368  ...   \n",
       "9                0.452381               0.583333               0.947368  ...   \n",
       "10               0.452381               0.583333               0.947368  ...   \n",
       "11               0.452381               0.583333               0.947368  ...   \n",
       "12               0.441860               0.583333               0.947368  ...   \n",
       "13               0.431818               0.560000               0.947368  ...   \n",
       "14               0.431818               0.560000               0.947368  ...   \n",
       "15               0.431818               0.560000               0.947368  ...   \n",
       "16               0.431818               0.560000               0.947368  ...   \n",
       "17               0.431818               0.576923               0.947368  ...   \n",
       "18               0.413043               0.576923               0.947368  ...   \n",
       "19               0.413043               0.576923               0.947368  ...   \n",
       "20               0.413043               0.576923               0.947368  ...   \n",
       "21               0.404255               0.576923               0.947368  ...   \n",
       "22               0.387755               0.576923               0.947368  ...   \n",
       "23               0.380000               0.576923               0.947368  ...   \n",
       "24               0.380000               0.555556               0.947368  ...   \n",
       "25               0.380000               0.555556               0.947368  ...   \n",
       "26               0.365385               0.535714               0.947368  ...   \n",
       "27               0.345455               0.535714               0.947368  ...   \n",
       "28               0.345455               0.535714               0.947368  ...   \n",
       "29               0.339286               0.535714               0.947368  ...   \n",
       "\n",
       "    split2_train_recall  split3_train_recall  split4_train_recall  \\\n",
       "0              0.627119             0.548023             0.573864   \n",
       "1              0.683616             0.627119             0.670455   \n",
       "2              0.740113             0.683616             0.710227   \n",
       "3              0.785311             0.706215             0.744318   \n",
       "4              0.824859             0.740113             0.755682   \n",
       "5              0.841808             0.768362             0.778409   \n",
       "6              0.847458             0.802260             0.789773   \n",
       "7              0.847458             0.813559             0.829545   \n",
       "8              0.847458             0.824859             0.846591   \n",
       "9              0.853107             0.830508             0.846591   \n",
       "10             0.858757             0.841808             0.852273   \n",
       "11             0.858757             0.841808             0.857955   \n",
       "12             0.870056             0.841808             0.857955   \n",
       "13             0.870056             0.841808             0.857955   \n",
       "14             0.870056             0.841808             0.857955   \n",
       "15             0.870056             0.841808             0.857955   \n",
       "16             0.870056             0.841808             0.863636   \n",
       "17             0.875706             0.853107             0.869318   \n",
       "18             0.881356             0.853107             0.869318   \n",
       "19             0.881356             0.858757             0.869318   \n",
       "20             0.881356             0.858757             0.875000   \n",
       "21             0.881356             0.858757             0.875000   \n",
       "22             0.881356             0.858757             0.875000   \n",
       "23             0.881356             0.858757             0.875000   \n",
       "24             0.881356             0.858757             0.875000   \n",
       "25             0.881356             0.864407             0.875000   \n",
       "26             0.881356             0.864407             0.875000   \n",
       "27             0.881356             0.864407             0.875000   \n",
       "28             0.881356             0.864407             0.875000   \n",
       "29             0.881356             0.864407             0.875000   \n",
       "\n",
       "    split5_train_recall  split6_train_recall  split7_train_recall  \\\n",
       "0              0.573864             0.562500             0.613636   \n",
       "1              0.647727             0.630682             0.687500   \n",
       "2              0.698864             0.687500             0.715909   \n",
       "3              0.732955             0.715909             0.755682   \n",
       "4              0.744318             0.727273             0.778409   \n",
       "5              0.789773             0.772727             0.789773   \n",
       "6              0.818182             0.801136             0.801136   \n",
       "7              0.829545             0.812500             0.806818   \n",
       "8              0.835227             0.823864             0.829545   \n",
       "9              0.835227             0.829545             0.835227   \n",
       "10             0.840909             0.835227             0.835227   \n",
       "11             0.846591             0.835227             0.846591   \n",
       "12             0.846591             0.835227             0.852273   \n",
       "13             0.846591             0.835227             0.863636   \n",
       "14             0.852273             0.835227             0.863636   \n",
       "15             0.852273             0.835227             0.863636   \n",
       "16             0.852273             0.840909             0.863636   \n",
       "17             0.852273             0.840909             0.869318   \n",
       "18             0.852273             0.846591             0.869318   \n",
       "19             0.857955             0.852273             0.869318   \n",
       "20             0.857955             0.852273             0.869318   \n",
       "21             0.857955             0.852273             0.869318   \n",
       "22             0.863636             0.852273             0.869318   \n",
       "23             0.863636             0.852273             0.869318   \n",
       "24             0.863636             0.852273             0.869318   \n",
       "25             0.863636             0.852273             0.869318   \n",
       "26             0.863636             0.852273             0.869318   \n",
       "27             0.875000             0.857955             0.869318   \n",
       "28             0.875000             0.857955             0.869318   \n",
       "29             0.875000             0.857955             0.869318   \n",
       "\n",
       "    split8_train_recall  split9_train_recall  mean_train_recall  \\\n",
       "0              0.636364             0.607955           0.612185   \n",
       "1              0.698864             0.687500           0.680239   \n",
       "2              0.744318             0.727273           0.724454   \n",
       "3              0.772727             0.738636           0.749978   \n",
       "4              0.784091             0.761364           0.771498   \n",
       "5              0.795455             0.772727           0.792485   \n",
       "6              0.818182             0.789773           0.812327   \n",
       "7              0.835227             0.818182           0.827080   \n",
       "8              0.857955             0.829545           0.838431   \n",
       "9              0.863636             0.846591           0.844665   \n",
       "10             0.863636             0.846591           0.848064   \n",
       "11             0.869318             0.852273           0.852038   \n",
       "12             0.869318             0.857955           0.854305   \n",
       "13             0.869318             0.857955           0.855441   \n",
       "14             0.869318             0.857955           0.856009   \n",
       "15             0.875000             0.857955           0.856577   \n",
       "16             0.880682             0.863636           0.859415   \n",
       "17             0.880682             0.863636           0.862811   \n",
       "18             0.886364             0.863636           0.864513   \n",
       "19             0.886364             0.863636           0.866214   \n",
       "20             0.886364             0.863636           0.866782   \n",
       "21             0.886364             0.863636           0.867347   \n",
       "22             0.886364             0.863636           0.867915   \n",
       "23             0.886364             0.869318           0.868484   \n",
       "24             0.886364             0.869318           0.868484   \n",
       "25             0.886364             0.875000           0.869617   \n",
       "26             0.892045             0.875000           0.870185   \n",
       "27             0.897727             0.875000           0.872458   \n",
       "28             0.897727             0.875000           0.872458   \n",
       "29             0.897727             0.875000           0.873588   \n",
       "\n",
       "    std_train_recall  \n",
       "0           0.054733  \n",
       "1           0.050286  \n",
       "2           0.043881  \n",
       "3           0.039589  \n",
       "4           0.037959  \n",
       "5           0.029289  \n",
       "6           0.021063  \n",
       "7           0.017190  \n",
       "8           0.013974  \n",
       "9           0.012015  \n",
       "10          0.010502  \n",
       "11          0.009997  \n",
       "12          0.011103  \n",
       "13          0.011414  \n",
       "14          0.011097  \n",
       "15          0.011881  \n",
       "16          0.011778  \n",
       "17          0.011843  \n",
       "18          0.012530  \n",
       "19          0.010798  \n",
       "20          0.011092  \n",
       "21          0.010509  \n",
       "22          0.010133  \n",
       "23          0.010036  \n",
       "24          0.010036  \n",
       "25          0.009789  \n",
       "26          0.010851  \n",
       "27          0.011025  \n",
       "28          0.011025  \n",
       "29          0.010104  \n",
       "\n",
       "[30 rows x 56 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_metric.cv_results_)#.to_csv('results/grid_search_cv_linear_regression_precision_recall.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53507ab-3d7c-49cf-8dc6-066d8c1cd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "df = pd.DataFrame(grid_metric.cv_results_)\n",
    "for score in ['mean_test_recall', 'mean_test_precision']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']], df[score],label=score)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
